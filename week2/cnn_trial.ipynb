{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np,sys\n",
    "#from sklearn.datasets import load_digits\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "import skimage.measure\n",
    "from scipy.signal import convolve2d\n",
    "from scipy import fftpack\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(12747)\n",
    "\n",
    "def ReLU(x):\n",
    "    mask  = (x >0) * 1.0 \n",
    "    return mask * x\n",
    "def d_ReLU(x):\n",
    "    mask  = (x >0) * 1.0 \n",
    "    return mask \n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def d_tanh(x):\n",
    "    return 1 - np.tanh(x) ** 2\n",
    "\n",
    "def arctanh(x):\n",
    "    return np.arctan(x)\n",
    "def d_arctan(x):\n",
    "    return 1 / ( 1 + x ** 2)\n",
    "\n",
    "def log(x):\n",
    "    return 1 / (1 + np.exp(-1 * x))\n",
    "def d_log(x):\n",
    "    return log(x) * ( 1 - log(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Prepare Data\n",
    "# data =load_digits()\n",
    "# image = data.images\n",
    "# label = data.target\n",
    "num_epoch = 300\n",
    "learning_rate = 0.1\n",
    "total_error = 0\n",
    "alpha = 0.00008\n",
    "\n",
    "w1a = np.random.randn(3,3) * 0.6 \n",
    "w1b = np.random.randn(3,3)* 0.6 \n",
    "\n",
    "w2a = np.random.randn(3,3)* 0.6\n",
    "w2b = np.random.randn(3,3)* 0.6\n",
    "w2c = np.random.randn(3,3)* 0.6\n",
    "w2d = np.random.randn(3,3)* 0.6\n",
    "\n",
    "w3 = np.random.randn(16,28)* 0.02 \n",
    "w4 = np.random.randn(28,36)* 0.02\n",
    "w5 = np.random.randn(36,1)* 0.02\n",
    "\n",
    "\n",
    "# 1. Prepare only one and only zero\n",
    "# only_zero_index = np.asarray(np.where(label == 0))\n",
    "# only_one_index  = np.asarray(np.where(label == 1))\n",
    "\n",
    "# # 1.5 prepare Label\n",
    "# only_zero_label = label[only_zero_index].T\n",
    "# only_one_label  = label[only_one_index].T\n",
    "# image_label = np.vstack((only_zero_label,only_one_label))\n",
    "\n",
    "# # 2. prepare matrix image\n",
    "# only_zero_image = np.squeeze(image[only_zero_index])\n",
    "# only_one_image = np.squeeze(image[only_one_index])\n",
    "# image_matrix = np.vstack((only_zero_image,only_one_image))\n",
    "\n",
    "\n",
    "x1 = np.array([\n",
    " [  0.,   0.,  11.,   8.,  12.,   5.,   0.,   0.],\n",
    " [  0.,   1.,  15.,  11.,   6.,  14.,   2.,   0.],\n",
    " [  0.,   4.,  11.,   0.,   0.,   9.,   4.,   0.],\n",
    " [  0.,   4.,   8.,   0.,   0.,   8.,   6.,   0.],\n",
    " [  0.,   6.,   7.,   0.,   0.,  11.,   3.,   0.],\n",
    " [  0.,   5.,   8.,   0.,   5.,  13.,   0.,   0.],\n",
    " [  0.,   3.,  13.,   5.,  15.,   3.,   0.,   0.],\n",
    " [  0.,   0.,   9.,  14.,   4.,   0.,   0.,   0.]])\n",
    "\n",
    "x2 = np.array([\n",
    " [  0.,   0.,   0.,   0.,  13.,  16.,   6.,   0.],\n",
    " [  0.,   0.,   3.,  11.,  16.,  16.,   5.,   0.],\n",
    " [  0.,   5.,  16.,  16.,  16.,  16.,   4.,   0.],\n",
    " [  0.,   4.,  10.,   9.,  16.,  16.,   4.,   0.],\n",
    " [  0.,   0.,   0.,   0.,  13.,  16.,   4.,   0.],\n",
    " [  0.,   0.,   0.,   0.,  12.,  16.,   4.,   0.],\n",
    " [  0.,   0.,   0.,   2.,  16.,  16.,   7.,   0.],\n",
    " [  0.,   0.,   0.,   1.,  12.,  14.,   5.,   0.]])\n",
    "\n",
    "x3 = np.array([\n",
    " [  0.,   0.,   0.,   1.,  12.,   7.,   0.   ,0.],\n",
    " [  0.,   0.,   0.,   9.,  16.,  16.,   1.   ,0.],\n",
    " [  0.,   1.,   7.,  15.,  16.,  14.,   0.   ,0.],\n",
    " [  0.,   4.,  16.,  16.,  16.,  16.,   0.   ,0.],\n",
    " [  0.,   0.,   0.,   3.,  16.,  16.,   0.   ,0.],\n",
    " [  0.,   0.,   0.,   2.,  16.,  16.,   3.  , 0.],\n",
    " [  0.,   0.,   0.,   6.,  16.,  16.,   0. ,  0.],\n",
    " [  0.,   0.,   0.,   3.,  15.,  13.,   0.,   0.]])\n",
    "\n",
    "x4 = np.array([\n",
    " [  0.,   0.,   8.,  12.,  12.,   1. ,  0.,   0.],\n",
    " [  0.,   3.,  16.,  16.,  14.,   9.,   0.,   0.],\n",
    " [  0.,   6.,  15.,   9.,   3.,  12.,   2.,   0.],\n",
    " [  0.,   7.,   9.,   0.,   0.,   9.,   7.,   0.],\n",
    " [  0.,   7.,   8.,   0.,   0.,   7.,   8.,   0.],\n",
    " [  0.,   5.,  10.,   0.,   0.,   7.,   9.,   0.],\n",
    " [  0.,   0.,  14.,  13.,  10.,  16.,   6.,   0.],\n",
    " [  0.,   0.,   5.,  13.,  11.,   4.,   0.,   0.]])\n",
    "\n",
    "\n",
    "image_matrix = np.array([x1,x2,x3,x4])\n",
    "image_label = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "v1a,v1b =0,0\n",
    "v2a,v2b,v2c,v2d =0,0,0,0\n",
    "v3,v4,v5 =0,0,0\n",
    "\n",
    "image_matrix,image_label = shuffle(image_matrix,image_label)\n",
    "\n",
    "image_test_label = image_label[:1]\n",
    "image_label = image_label[1:]\n",
    "\n",
    "image_test_matrix = image_matrix[:1,:,:]\n",
    "image_matrix = image_matrix[1:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iter :  0  Current cost:  0.375919098524\n",
      "Current iter :  1  Current cost:  0.374628094432\n",
      "Current iter :  2  Current cost:  0.373446297829\n",
      "Current iter :  3  Current cost:  0.372308317222\n",
      "Current iter :  4  Current cost:  0.371165655414\n",
      "Current iter :  5  Current cost:  0.369988450701\n",
      "Current iter :  6  Current cost:  0.3687583569\n",
      "Current iter :  7  Current cost:  0.367464049648\n",
      "Current iter :  8  Current cost:  0.366098919954\n",
      "Current iter :  9  Current cost:  0.364659548381\n",
      "Current iter :  10  Current cost:  0.363145418818\n",
      "Current iter :  11  Current cost:  0.361559762914\n",
      "Current iter :  12  Current cost:  0.359910408089\n",
      "Current iter :  13  Current cost:  0.35821031482\n",
      "Current iter :  14  Current cost:  0.356477745567\n",
      "Current iter :  15  Current cost:  0.354735505097\n",
      "Current iter :  16  Current cost:  0.353008987546\n",
      "Current iter :  17  Current cost:  0.351323846411\n",
      "Current iter :  18  Current cost:  0.349704131041\n",
      "Current iter :  19  Current cost:  0.34817080897\n",
      "Current iter :  20  Current cost:  0.34674041693\n",
      "Current iter :  21  Current cost:  0.345424116548\n",
      "Current iter :  22  Current cost:  0.344227592781\n",
      "Current iter :  23  Current cost:  0.343151716315\n",
      "Current iter :  24  Current cost:  0.342193485567\n",
      "Current iter :  25  Current cost:  0.34134694375\n",
      "Current iter :  26  Current cost:  0.340604048167\n",
      "Current iter :  27  Current cost:  0.339955510594\n",
      "Current iter :  28  Current cost:  0.339391564693\n",
      "Current iter :  29  Current cost:  0.338902602419\n",
      "Current iter :  30  Current cost:  0.338479663352\n",
      "Current iter :  31  Current cost:  0.338114801254\n",
      "Current iter :  32  Current cost:  0.337801348958\n",
      "Current iter :  33  Current cost:  0.337534050443\n",
      "Current iter :  34  Current cost:  0.337308946654\n",
      "Current iter :  35  Current cost:  0.337122825916\n",
      "Current iter :  36  Current cost:  0.336972077417\n",
      "Current iter :  37  Current cost:  0.336851152721\n",
      "Current iter :  38  Current cost:  0.336751712137\n",
      "Current iter :  39  Current cost:  0.336664068309\n",
      "Current iter :  40  Current cost:  0.336580744934\n",
      "Current iter :  41  Current cost:  0.336498856113\n",
      "Current iter :  42  Current cost:  0.336419026727\n",
      "Current iter :  43  Current cost:  0.336342833332\n",
      "Current iter :  44  Current cost:  0.336271381716\n",
      "Current iter :  45  Current cost:  0.336204965952\n",
      "Current iter :  46  Current cost:  0.336103418603\n",
      "Current iter :  47  Current cost:  0.33600720459\n",
      "Current iter :  48  Current cost:  0.335912577182\n",
      "Current iter :  49  Current cost:  0.335819096109\n",
      "Current iter :  50  Current cost:  0.335726666624\n",
      "Current iter :  51  Current cost:  0.335635327115\n",
      "Current iter :  52  Current cost:  0.335545190865\n",
      "Current iter :  53  Current cost:  0.335456471451\n",
      "Current iter :  54  Current cost:  0.335369554829\n",
      "Current iter :  55  Current cost:  0.335285136875\n",
      "Current iter :  56  Current cost:  0.33520448197\n",
      "Current iter :  57  Current cost:  0.335129942414\n",
      "Current iter :  58  Current cost:  0.335066027151\n",
      "Current iter :  59  Current cost:  0.335021015007\n",
      "Current iter :  60  Current cost:  0.33500026315\n",
      "Current iter :  61  Current cost:  0.334889148278\n",
      "Current iter :  62  Current cost:  0.334213308325\n",
      "Current iter :  63  Current cost:  0.333856997775\n",
      "Current iter :  64  Current cost:  0.333755597615\n",
      "Current iter :  65  Current cost:  0.333618912\n",
      "Current iter :  66  Current cost:  0.333499201591\n",
      "Current iter :  67  Current cost:  0.333364651124\n",
      "Current iter :  68  Current cost:  0.333241644564\n",
      "Current iter :  69  Current cost:  0.333110736937\n",
      "Current iter :  70  Current cost:  0.332987036239\n",
      "Current iter :  71  Current cost:  0.332857957479\n",
      "Current iter :  72  Current cost:  0.332732723279\n",
      "Current iter :  73  Current cost:  0.332602482511\n",
      "Current iter :  74  Current cost:  0.332473912706\n",
      "Current iter :  75  Current cost:  0.33234007985\n",
      "Current iter :  76  Current cost:  0.332206492168\n",
      "Current iter :  77  Current cost:  0.332066947267\n",
      "Current iter :  78  Current cost:  0.33192642576\n",
      "Current iter :  79  Current cost:  0.33177901554\n",
      "Current iter :  80  Current cost:  0.331630450741\n",
      "Current iter :  81  Current cost:  0.331475606154\n",
      "Current iter :  82  Current cost:  0.331321967271\n",
      "Current iter :  83  Current cost:  0.33116362201\n",
      "Current iter :  84  Current cost:  0.331008454618\n",
      "Current iter :  85  Current cost:  0.330847389877\n",
      "Current iter :  86  Current cost:  0.330689738049\n",
      "Current iter :  87  Current cost:  0.330522851057\n",
      "Current iter :  88  Current cost:  0.330360281833\n",
      "Current iter :  89  Current cost:  0.330183851237\n",
      "Current iter :  90  Current cost:  0.330014954113\n",
      "Current iter :  91  Current cost:  0.329825034527\n",
      "Current iter :  92  Current cost:  0.329650146259\n",
      "Current iter :  93  Current cost:  0.329441293419\n",
      "Current iter :  94  Current cost:  0.329263874585\n",
      "Current iter :  95  Current cost:  0.329026277792\n",
      "Current iter :  96  Current cost:  0.328857069099\n",
      "Current iter :  97  Current cost:  0.328569271424\n",
      "Current iter :  98  Current cost:  0.328438464008\n",
      "Current iter :  99  Current cost:  0.328046382729\n",
      "Current iter :  100  Current cost:  0.328041303316\n",
      "Current iter :  101  Current cost:  0.327392415322\n",
      "Current iter :  102  Current cost:  0.327785023074\n",
      "Current iter :  103  Current cost:  0.326402750792\n",
      "Current iter :  104  Current cost:  0.328115445562\n",
      "Current iter :  105  Current cost:  0.32461555542\n",
      "Current iter :  106  Current cost:  0.330161900146\n",
      "Current iter :  107  Current cost:  0.322235346663\n",
      "Current iter :  108  Current cost:  0.32979119813\n",
      "Current iter :  109  Current cost:  0.321216467237\n",
      "Current iter :  110  Current cost:  0.331879333789\n",
      "Current iter :  111  Current cost:  0.320041854335\n",
      "Current iter :  112  Current cost:  0.326846913543\n",
      "Current iter :  113  Current cost:  0.321155834938\n",
      "Current iter :  114  Current cost:  0.327493556255\n",
      "Current iter :  115  Current cost:  0.319219552679\n",
      "Current iter :  116  Current cost:  0.326583638971\n",
      "Current iter :  117  Current cost:  0.319662711715\n",
      "Current iter :  118  Current cost:  0.321935099541\n",
      "Current iter :  119  Current cost:  0.323160441912\n",
      "Current iter :  120  Current cost:  0.318875994221\n",
      "Current iter :  121  Current cost:  0.321249112364\n",
      "Current iter :  122  Current cost:  0.320363675567\n",
      "Current iter :  123  Current cost:  0.319200855673\n",
      "Current iter :  124  Current cost:  0.31964901347\n",
      "Current iter :  125  Current cost:  0.319426342199\n",
      "Current iter :  126  Current cost:  0.315339999956\n",
      "Current iter :  127  Current cost:  0.316881880446\n",
      "Current iter :  128  Current cost:  0.320336039235\n",
      "Current iter :  129  Current cost:  0.319031664662\n",
      "Current iter :  130  Current cost:  0.32444960375\n",
      "Current iter :  131  Current cost:  0.345955069937\n",
      "Current iter :  132  Current cost:  0.334541747487\n",
      "Current iter :  133  Current cost:  0.331238540219\n",
      "Current iter :  134  Current cost:  0.333059133814\n",
      "Current iter :  135  Current cost:  0.329354729241\n",
      "Current iter :  136  Current cost:  0.336906022929\n",
      "Current iter :  137  Current cost:  0.326162187019\n",
      "Current iter :  138  Current cost:  0.341413505819\n",
      "Current iter :  139  Current cost:  0.324171265\n",
      "Current iter :  140  Current cost:  0.351861037533\n",
      "Current iter :  141  Current cost:  0.334083553318\n",
      "Current iter :  142  Current cost:  0.331284118382\n",
      "Current iter :  143  Current cost:  0.33546877875\n",
      "Current iter :  144  Current cost:  0.326373793059\n",
      "Current iter :  145  Current cost:  0.334050316681\n",
      "Current iter :  146  Current cost:  0.321795803556\n",
      "Current iter :  147  Current cost:  0.324517510222\n",
      "Current iter :  148  Current cost:  0.322666327537\n",
      "Current iter :  149  Current cost:  0.313435210636\n",
      "Current iter :  150  Current cost:  0.331070731359\n",
      "Current iter :  151  Current cost:  0.318316103424\n",
      "Current iter :  152  Current cost:  0.318688270477\n",
      "Current iter :  153  Current cost:  0.316235484815\n",
      "Current iter :  154  Current cost:  0.323842198201\n",
      "Current iter :  155  Current cost:  0.343575731752\n",
      "Current iter :  156  Current cost:  0.346047808831\n",
      "Current iter :  157  Current cost:  0.345547901851\n",
      "Current iter :  158  Current cost:  0.336118072824\n",
      "Current iter :  159  Current cost:  0.352299822333\n",
      "Current iter :  160  Current cost:  0.325671352815\n",
      "Current iter :  161  Current cost:  0.36788974577\n",
      "Current iter :  162  Current cost:  0.317469570859\n",
      "Current iter :  163  Current cost:  0.341948372584\n",
      "Current iter :  164  Current cost:  0.343606860281\n",
      "Current iter :  165  Current cost:  0.346366816884\n",
      "Current iter :  166  Current cost:  0.335079199805\n",
      "Current iter :  167  Current cost:  0.348924955004\n",
      "Current iter :  168  Current cost:  0.323529078928\n",
      "Current iter :  169  Current cost:  0.338605704003\n",
      "Current iter :  170  Current cost:  0.32678156218\n",
      "Current iter :  171  Current cost:  0.368318881164\n",
      "Current iter :  172  Current cost:  0.321905495986\n",
      "Current iter :  173  Current cost:  0.297751124094\n",
      "Current iter :  174  Current cost:  0.352181798823\n",
      "Current iter :  175  Current cost:  0.325799980378\n",
      "Current iter :  176  Current cost:  0.366938756567\n",
      "Current iter :  177  Current cost:  0.368592944044\n",
      "Current iter :  178  Current cost:  0.351098276886\n",
      "Current iter :  179  Current cost:  0.361858034659\n",
      "Current iter :  180  Current cost:  0.345859950895\n",
      "Current iter :  181  Current cost:  0.260373519943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iter :  182  Current cost:  0.236963404558\n",
      "Current iter :  183  Current cost:  0.209617296821\n",
      "Current iter :  184  Current cost:  0.232386084732\n",
      "Current iter :  185  Current cost:  0.197784450828\n",
      "Current iter :  186  Current cost:  0.203438504486\n",
      "Current iter :  187  Current cost:  0.15928673394\n",
      "Current iter :  188  Current cost:  0.121811057259\n",
      "Current iter :  189  Current cost:  0.09274282853\n",
      "Current iter :  190  Current cost:  0.0518492617208\n",
      "Current iter :  191  Current cost:  0.0348242401927\n",
      "Current iter :  192  Current cost:  0.0297588927402\n",
      "Current iter :  193  Current cost:  0.0252993638963\n",
      "Current iter :  194  Current cost:  0.0226821910577\n",
      "Current iter :  195  Current cost:  0.0204383214037\n",
      "Current iter :  196  Current cost:  0.0183215059454\n",
      "Current iter :  197  Current cost:  0.0165712729678\n",
      "Current iter :  198  Current cost:  0.0152678617389\n",
      "Current iter :  199  Current cost:  0.0141334385383\n",
      "Current iter :  200  Current cost:  0.0131351820726\n",
      "Current iter :  201  Current cost:  0.0122510335727\n",
      "Current iter :  202  Current cost:  0.0114631410207\n",
      "Current iter :  203  Current cost:  0.0107573059715\n",
      "Current iter :  204  Current cost:  0.0101216386561\n",
      "Current iter :  205  Current cost:  0.00954477960699\n",
      "Current iter :  206  Current cost:  0.00901927758605\n",
      "Current iter :  207  Current cost:  0.00853649772286\n",
      "Current iter :  208  Current cost:  0.00809063614025\n",
      "Current iter :  209  Current cost:  0.00767369570416\n",
      "Current iter :  210  Current cost:  0.00727676892745\n",
      "Current iter :  211  Current cost:  0.00688816461947\n",
      "Current iter :  212  Current cost:  0.00647874575335\n",
      "Current iter :  213  Current cost:  0.00596817636032\n",
      "Current iter :  214  Current cost:  0.0052512158972\n",
      "Current iter :  215  Current cost:  0.0048619542233\n",
      "Current iter :  216  Current cost:  0.00464803968751\n",
      "Current iter :  217  Current cost:  0.00446538458823\n",
      "Current iter :  218  Current cost:  0.00429791870202\n",
      "Current iter :  219  Current cost:  0.00413888053106\n",
      "Current iter :  220  Current cost:  0.00398205043464\n",
      "Current iter :  221  Current cost:  0.00382147462146\n",
      "Current iter :  222  Current cost:  0.00365477756846\n",
      "Current iter :  223  Current cost:  0.0034973706507\n",
      "Current iter :  224  Current cost:  0.00336755607912\n",
      "Current iter :  225  Current cost:  0.00326067748221\n",
      "Current iter :  226  Current cost:  0.00316722991914\n",
      "Current iter :  227  Current cost:  0.00308272684394\n",
      "Current iter :  228  Current cost:  0.00300447940976\n",
      "Current iter :  229  Current cost:  0.00293125432559\n",
      "Current iter :  230  Current cost:  0.00286218183345\n",
      "Current iter :  231  Current cost:  0.00279695111831\n",
      "Current iter :  232  Current cost:  0.00273489596708\n",
      "Current iter :  233  Current cost:  0.00267574876678\n",
      "Current iter :  234  Current cost:  0.00261921983292\n",
      "Current iter :  235  Current cost:  0.00256519719013\n",
      "Current iter :  236  Current cost:  0.00251349787823\n",
      "Current iter :  237  Current cost:  0.0024638218839\n",
      "Current iter :  238  Current cost:  0.00241606101286\n",
      "Current iter :  239  Current cost:  0.00237017813915\n",
      "Current iter :  240  Current cost:  0.0023260671363\n",
      "Current iter :  241  Current cost:  0.00228350157665\n",
      "Current iter :  242  Current cost:  0.00224241994071\n",
      "Current iter :  243  Current cost:  0.00220281450353\n",
      "Current iter :  244  Current cost:  0.00216461621368\n",
      "Current iter :  245  Current cost:  0.00212764180045\n",
      "Current iter :  246  Current cost:  0.00209185397721\n",
      "Current iter :  247  Current cost:  0.00205725947617\n",
      "Current iter :  248  Current cost:  0.00202381057227\n",
      "Current iter :  249  Current cost:  0.00199135373925\n",
      "Current iter :  250  Current cost:  0.00195986588442\n",
      "Current iter :  251  Current cost:  0.00192936164348\n",
      "Current iter :  252  Current cost:  0.00189980666892\n",
      "Current iter :  253  Current cost:  0.0018710802533\n",
      "Current iter :  254  Current cost:  0.00184317689174\n",
      "Current iter :  255  Current cost:  0.00181610443064\n",
      "Current iter :  256  Current cost:  0.00178974854758\n",
      "Current iter :  257  Current cost:  0.0017640843221\n",
      "Current iter :  258  Current cost:  0.00173913018418\n",
      "Current iter :  259  Current cost:  0.00171487303548\n",
      "Current iter :  260  Current cost:  0.00169129310814\n",
      "Current iter :  261  Current cost:  0.00166829114994\n",
      "Current iter :  262  Current cost:  0.0016458619486\n",
      "Current iter :  263  Current cost:  0.00162402903335\n",
      "Current iter :  264  Current cost:  0.00160277671167\n",
      "Current iter :  265  Current cost:  0.00158201759211\n",
      "Current iter :  266  Current cost:  0.00156174882538\n",
      "Current iter :  267  Current cost:  0.00154199470565\n",
      "Current iter :  268  Current cost:  0.0015227423461\n",
      "Current iter :  269  Current cost:  0.00150391438265\n",
      "Current iter :  270  Current cost:  0.00148550945187\n",
      "Current iter :  271  Current cost:  0.00146755216486\n",
      "Current iter :  272  Current cost:  0.00145003155934\n",
      "Current iter :  273  Current cost:  0.00143287885846\n",
      "Current iter :  274  Current cost:  0.00141609358558\n",
      "Current iter :  275  Current cost:  0.00139970038142\n",
      "Current iter :  276  Current cost:  0.00138368958638\n",
      "Current iter :  277  Current cost:  0.00136799985377\n",
      "Current iter :  278  Current cost:  0.00135263118023\n",
      "Current iter :  279  Current cost:  0.00133760805167\n",
      "Current iter :  280  Current cost:  0.00132292166695\n",
      "Current iter :  281  Current cost:  0.00130851716335\n",
      "Current iter :  282  Current cost:  0.00129439127952\n",
      "Current iter :  283  Current cost:  0.00128059621636\n",
      "Current iter :  284  Current cost:  0.00126706044913\n",
      "Current iter :  285  Current cost:  0.00125379275498\n",
      "Current iter :  286  Current cost:  0.00124080888448\n",
      "Current iter :  287  Current cost:  0.001228057709\n",
      "Current iter :  288  Current cost:  0.00121554109357\n",
      "Current iter :  289  Current cost:  0.00120328103519\n",
      "Current iter :  290  Current cost:  0.00119127404219\n",
      "Current iter :  291  Current cost:  0.00117947390525\n",
      "Current iter :  292  Current cost:  0.0011678822229\n",
      "Current iter :  293  Current cost:  0.00115652065148\n",
      "Current iter :  294  Current cost:  0.00114538561765\n",
      "Current iter :  295  Current cost:  0.0011344353027\n",
      "Current iter :  296  Current cost:  0.00112366690944\n",
      "Current iter :  297  Current cost:  0.00111309679211\n",
      "Current iter :  298  Current cost:  0.00110272775918\n",
      "Current iter :  299  Current cost:  0.00109255743037\n",
      "\n",
      "\n",
      "---- Ground Truth -----\n",
      "[[0]]\n",
      "---- Predicted  -----\n",
      "[ 0.03438341]\n",
      "---- Predicted Rounded -----\n",
      "[ 0.]\n"
     ]
    }
   ],
   "source": [
    "for iter in range(num_epoch):\n",
    "    for image_index in range(len(image_matrix)):\n",
    "        \n",
    "        current_image = image_matrix[image_index]\n",
    "        current_image_label = image_label[image_index]\n",
    "\n",
    "        l1aIN,l1bIN = np.pad(current_image,1,mode='constant'),np.pad(current_image,1,mode='constant')\n",
    "\n",
    "        l1a = convolve2d(l1aIN,w1a,mode='valid')\n",
    "        l1aA = ReLU(l1a)\n",
    "        l1aM = skimage.measure.block_reduce(l1aA, block_size=(2,2), func=np.max)\n",
    "\n",
    "        l1b = convolve2d(l1bIN,w1b,mode='valid')\n",
    "        l1bA = arctanh(l1b)\n",
    "        l1bM = skimage.measure.block_reduce(l1bA, block_size=(2,2), func=np.max)\n",
    "\n",
    "        l2aIN,l2bIN =  np.pad(l1aM,1,mode='constant'),np.pad(l1aM,1,mode='constant')\n",
    "        l2cIN,l2dIN =  np.pad(l1bM,1,mode='constant'),np.pad(l1bM,1,mode='constant')\n",
    "\n",
    "        l2a = convolve2d(l2aIN,w1b,mode='valid')\n",
    "        l2aA = arctanh(l2a)\n",
    "        l2aM = skimage.measure.block_reduce(l2aA, block_size=(2,2), func=np.max) \n",
    "\n",
    "        l2b = convolve2d(l2bIN,w1b,mode='valid')\n",
    "        l2bA = ReLU(l2b)\n",
    "        l2bM = skimage.measure.block_reduce(l2bA, block_size=(2,2), func=np.max)\n",
    "\n",
    "        l2c = convolve2d(l2cIN,w1b,mode='valid')\n",
    "        l2cA = arctanh(l2c)\n",
    "        l2cM = skimage.measure.block_reduce(l2cA, block_size=(2,2), func=np.max)\n",
    "\n",
    "        l2d = convolve2d(l2dIN,w1b,mode='valid')\n",
    "        l2dA = tanh(l2d)\n",
    "        l2dM = skimage.measure.block_reduce(l2dA, block_size=(2,2), func=np.max)\n",
    "\n",
    "        l3IN = np.expand_dims(np.hstack([l2aM.ravel(),l2bM.ravel(),l2cM.ravel(),l2dM.ravel() ]),axis=0)\n",
    "\n",
    "        l3 = l3IN.dot(w3)\n",
    "        l3A = arctanh(l3)\n",
    "\n",
    "        l4 = l3A.dot(w4)\n",
    "        l4A = tanh(l4)\n",
    "\n",
    "        l5 = l4A.dot(w5)\n",
    "        l5A = log(l5)\n",
    "\n",
    "        cost = np.square(l5A - current_image_label).sum() * 0.5\n",
    "        total_error += cost\n",
    "\n",
    "        grad_5_part_1 = l5A - current_image_label\n",
    "        grad_5_part_2 = d_log(l5)\n",
    "        grad_5_part_3 =l4A\n",
    "        grad_5 =grad_5_part_3.T.dot(grad_5_part_1 * grad_5_part_2)\n",
    "\n",
    "        grad_4_part_1 = (grad_5_part_1 * grad_5_part_2).dot(w5.T)\n",
    "        grad_4_part_2 = d_tanh(l4)\n",
    "        grad_4_part_3 =l3A\n",
    "        grad_4 =  grad_4_part_3.T.dot(grad_4_part_1 * grad_4_part_2 )\n",
    "\n",
    "        grad_3_part_1 = (grad_4_part_1 * grad_4_part_2).dot(w4.T)\n",
    "        grad_3_part_2 = d_arctan(l3)\n",
    "        grad_3_part_3 =l3IN\n",
    "        grad_3 = grad_3_part_3.T.dot(grad_3_part_1 * grad_3_part_2)  \n",
    "\n",
    "        grad_2_part_IN = (grad_3_part_1 * grad_3_part_2).dot(w3.T)\n",
    "        \n",
    "        grad_2_window_a = np.reshape(grad_2_part_IN[:,:4],(2,2))\n",
    "        grad_2_mask_a =  np.equal(l2aA, l2aM.repeat(2, axis=0).repeat(2, axis=1)).astype(int) \n",
    "        grad_2_part_1_a =  grad_2_mask_a *  grad_2_window_a.repeat(2, axis=0).repeat(2, axis=1)\n",
    "        grad_2_part_2_a = d_arctan(l2a)\n",
    "        grad_2_part_3_a = l2aIN\n",
    "        grad_2_a = np.rot90(convolve2d(grad_2_part_3_a,np.rot90(grad_2_part_2_a * grad_2_part_1_a,2),mode='valid'),2)\n",
    "\n",
    "        grad_2_window_b = np.reshape(grad_2_part_IN[:,4:8],(2,2))\n",
    "        grad_2_mask_b =  np.equal(l2bA, l2bM.repeat(2, axis=0).repeat(2, axis=1)).astype(int) \n",
    "        grad_2_part_1_b = grad_2_mask_b *  grad_2_window_b.repeat(2, axis=0).repeat(2, axis=1)\n",
    "        grad_2_part_2_b = d_ReLU(l2b)\n",
    "        grad_2_part_3_b = l2bIN\n",
    "        grad_2_b = np.rot90(convolve2d(grad_2_part_3_b,np.rot90(grad_2_part_2_b * grad_2_part_1_b,2),mode='valid'),2)\n",
    "\n",
    "        grad_2_window_c = np.reshape(grad_2_part_IN[:,8:12],(2,2))\n",
    "        grad_2_mask_c =  np.equal(l2cA, l2cM.repeat(2, axis=0).repeat(2, axis=1)).astype(int) \n",
    "        grad_2_part_1_c = grad_2_mask_c *  grad_2_window_c.repeat(2, axis=0).repeat(2, axis=1)\n",
    "        grad_2_part_2_c = d_arctan(l2c)\n",
    "        grad_2_part_3_c = l2cIN\n",
    "        grad_2_c = np.rot90(convolve2d(grad_2_part_3_c,np.rot90( grad_2_part_2_c * grad_2_part_1_c,2),mode='valid'),2)\n",
    "\n",
    "        grad_2_window_d = np.reshape(grad_2_part_IN[:,12:],(2,2))\n",
    "        grad_2_mask_d =  np.equal(l2dA, l2dM.repeat(2, axis=0).repeat(2, axis=1)).astype(int) \n",
    "        grad_2_part_1_d =  grad_2_mask_d *  grad_2_window_d.repeat(2, axis=0).repeat(2, axis=1)\n",
    "        grad_2_part_2_d = d_tanh(l2d)\n",
    "        grad_2_part_3_d = l2dIN\n",
    "        grad_2_d = np.rot90(convolve2d(grad_2_part_3_d,np.rot90( grad_2_part_2_d * grad_2_part_1_d,2),mode='valid'),2)\n",
    "                    \n",
    "        grad_1_part_IN_a =np.rot90(  grad_2_part_1_a * grad_2_part_2_a ,2)\n",
    "        grad_1_part_IN_a_padded = np.pad(w2a,2,mode='constant')\n",
    "        grad_1_part_a = convolve2d(grad_1_part_IN_a_padded,grad_1_part_IN_a,mode='valid')    \n",
    "\n",
    "        grad_1_part_IN_b = np.rot90( grad_2_part_2_b * grad_2_part_1_b,2)\n",
    "        grad_1_part_IN_b_padded = np.pad(w2b,2,mode='constant')\n",
    "        grad_1_part_b = convolve2d(grad_1_part_IN_b_padded,grad_1_part_IN_b,mode='valid')    \n",
    "\n",
    "        grad_1_window_a = grad_1_part_a + grad_1_part_b\n",
    "        grad_1_mask_a =  np.equal(l1aA, l1aM.repeat(2, axis=0).repeat(2, axis=1)).astype(int) \n",
    "        grad_1_part_1_a =  grad_1_mask_a *  grad_1_window_a.repeat(2, axis=0).repeat(2, axis=1) \n",
    "        grad_1_part_2_a = d_ReLU(l1a)\n",
    "        grad_1_part_3_a = l1aIN\n",
    "        grad_1_a = np.rot90(convolve2d(grad_1_part_3_a,np.rot90( grad_1_part_1_a *grad_1_part_2_a,2),mode='valid'),2)\n",
    "        \n",
    "        grad_1_part_IN_c = np.rot90(grad_2_part_1_c * grad_2_part_2_c,2)\n",
    "        grad_1_part_IN_c_padded = np.pad(w2c,2,mode='constant')\n",
    "        grad_1_part_c = convolve2d(grad_1_part_IN_c_padded,grad_1_part_IN_c,mode='valid')    \n",
    "\n",
    "        grad_1_part_IN_d = np.rot90(grad_2_part_1_d * grad_2_part_2_d ,2)\n",
    "        grad_1_part_IN_d_padded = np.pad(w2d,2,mode='constant')\n",
    "        grad_1_part_d = convolve2d(grad_1_part_IN_d_padded,grad_1_part_IN_d,mode='valid')    \n",
    "\n",
    "        grad_1_window_b = grad_1_part_c + grad_1_part_d\n",
    "        grad_1_mask_b =  np.equal(l1bA, l1bM.repeat(2, axis=0).repeat(2, axis=1)).astype(int) \n",
    "        grad_1_part_1_b =  grad_1_mask_b *  grad_1_window_b.repeat(2, axis=0).repeat(2, axis=1) \n",
    "        grad_1_part_2_b = d_arctan(l1b)\n",
    "        grad_1_part_3_b = l1bIN\n",
    "        grad_1_b = np.rot90(convolve2d(grad_1_part_3_b, np.rot90(grad_1_part_1_b *grad_1_part_2_b,2),mode='valid'),2)\n",
    "        \n",
    "        v5 = alpha * v5 + learning_rate * grad_5 \n",
    "        v4 = alpha * v4 + learning_rate * grad_4 \n",
    "        v3 = alpha * v3 + learning_rate * grad_3 \n",
    "\n",
    "        v2a = alpha * v2a + learning_rate * grad_2_a \n",
    "        v2b = alpha * v2b + learning_rate * grad_2_b \n",
    "        v2c = alpha * v2c + learning_rate * grad_2_c \n",
    "        v2d = alpha * v2d + learning_rate * grad_2_d \n",
    "\n",
    "        v1b = alpha * v1b + learning_rate * grad_1_b  \n",
    "        v1a = alpha * v1a + learning_rate * grad_1_a\n",
    "        \n",
    "        w5 = w5 - v5  \n",
    "        w4 = w4 - v4 \n",
    "        w3 = w3 - v3\n",
    "            \n",
    "        w2d = w2d - v2d  \n",
    "        w2c = w2c - v2c\n",
    "        w2b = w2b - v2b\n",
    "        w2a = w2a - v2a  \n",
    "\n",
    "        w1b = w1b - v1b \n",
    "        w1a = w1a - v1a  \n",
    "\n",
    "\n",
    "    print(\"Current iter : \",iter, \" Current cost: \", total_error,end='\\n')\n",
    "    total_error = 0\n",
    "\n",
    "print('\\n')\n",
    "predict = np.array([])\n",
    "for image_index in range(len(image_test_matrix)):\n",
    "    \n",
    "    current_image = image_test_matrix[image_index]\n",
    "\n",
    "    l1aIN,l1bIN = np.pad(current_image,1,mode='constant'),np.pad(current_image,1,mode='constant')\n",
    "\n",
    "    l1a = convolve2d(l1aIN,w1a,mode='valid')\n",
    "    l1aA = ReLU(l1a)\n",
    "    l1aM = skimage.measure.block_reduce(l1aA, block_size=(2,2), func=np.max)\n",
    "\n",
    "    l1b = convolve2d(l1bIN,w1b,mode='valid')\n",
    "    l1bA = arctanh(l1b)\n",
    "    l1bM = skimage.measure.block_reduce(l1bA, block_size=(2,2), func=np.max)\n",
    "\n",
    "    l2aIN,l2bIN =  np.pad(l1aM,1,mode='constant'),np.pad(l1aM,1,mode='constant')\n",
    "    l2cIN,l2dIN =  np.pad(l1bM,1,mode='constant'),np.pad(l1bM,1,mode='constant')\n",
    "\n",
    "    l2a = convolve2d(l2aIN,w1b,mode='valid')\n",
    "    l2aA = arctanh(l2a)\n",
    "    l2aM = skimage.measure.block_reduce(l2aA, block_size=(2,2), func=np.max) \n",
    "\n",
    "    l2b = convolve2d(l2bIN,w1b,mode='valid')\n",
    "    l2bA = ReLU(l2b)\n",
    "    l2bM = skimage.measure.block_reduce(l2bA, block_size=(2,2), func=np.max)\n",
    "\n",
    "    l2c = convolve2d(l2cIN,w1b,mode='valid')\n",
    "    l2cA = arctanh(l2c)\n",
    "    l2cM = skimage.measure.block_reduce(l2cA, block_size=(2,2), func=np.max)\n",
    "\n",
    "    l2d = convolve2d(l2dIN,w1b,mode='valid')\n",
    "    l2dA = tanh(l2d)\n",
    "    l2dM = skimage.measure.block_reduce(l2dA, block_size=(2,2), func=np.max)\n",
    "\n",
    "    l3IN = np.expand_dims(np.hstack([l2aM.ravel(),l2bM.ravel(),l2cM.ravel(),l2dM.ravel() ]),axis=0)\n",
    "\n",
    "    l3 = l3IN.dot(w3)\n",
    "    l3A = arctanh(l3)\n",
    "\n",
    "    l4 = l3A.dot(w4)\n",
    "    l4A = tanh(l4)\n",
    "\n",
    "    l5 = l4A.dot(w5)\n",
    "    l5A = log(l5)\n",
    "\n",
    "    predict = np.append(predict,l5A)\n",
    "\n",
    "\n",
    "print('---- Ground Truth -----')\n",
    "print(image_test_label.T)\n",
    "\n",
    "print('---- Predicted  -----')\n",
    "print(predict.T)\n",
    "\n",
    "print('---- Predicted Rounded -----')\n",
    "print(np.round(predict.T))\n",
    "# -- end code --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
